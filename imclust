#!/usr/bin/env -S python3 -u # -*- python -*-
import os,sys,time,re,types

# import a silent numpy
import numpy as np
np.warnings.filterwarnings("ignore",category=np.VisibleDeprecationWarning)

# available vs. default perception models (to transform input picture into vector of numbers)
MODELS = ("none","resnet50")
MODEL = "resnet50"

# available vs. default dimensionality reduction methods
REDIMS = ("none","pca") # TODO: autoencoders
REDIM = "pca"

# available vs. default clustering methods
CLUSTS = ("km","bkm")
CLUST = "km"

# available vs. default cluster-centers sorting methods
SORTS = ("none","size","tsp")
SORT = "tsp"

# TODO: available vs. default intra-cluster sorting methods
CSORTS = ("none","dist","tsp")
CSORT = "tsp"

# TODO: available vs. default clustering evaluation methods
EVALS = ("none","tsp")
EVAL = "none"

# TODO: available vs. default clusters evaluation methods
CEVALS = ("none","tsp")
CEVAL = "none"

# batchsize and dimensionality reduction size
BATCHSIZE = 2048
REDIMSIZE = 3072 # target size of vector after reduction
REDIMPATS = 8192 # number of patterns to train "reductor"

# no. of loading threads
THREADS = 8

# ------------------------------------------------------------------------------------

def vtime(): return time.clock_gettime(time.CLOCK_MONOTONIC)

def MSG1(str): print(f"{str:>18s}:",end=" ",file=sys.stderr)	# start
def MSG2(str): print(str,end=" ",file=sys.stderr)		# continue
def MSGC(str): print(str,end="",file=sys.stderr)		# progressbar character
def MSG3(str): print(str,file=sys.stderr)			# end
def MSG(hdr,str): MSG1(hdr); MSG3(str)				# hdr+string util function
def MSGE(str): MSG1("error"); MSG3(str); exit()			# error util function

def MSGP(j): # progress-overwrite function, j is progress index
  ch = "."
  if (j+1)% 5==0: ch = ","
  if (j+1)%10==0: ch = ":"
  MSGC(f"\b{ch}")

# return metric number
def metric(num):
  ret = None
  if num > 107374182400: ret = f"{num/1073741824:.0f}G"
  elif num > 1073741824: ret = f"{num/1073741824:.1f}G"
  elif  num > 104857600: ret = f"{num/1048576:.0f}M"
  elif    num > 1048576: ret = f"{num/1048576:.1f}M"
  elif     num > 102400: ret = f"{num/1024:.0f}k"
  elif       num > 1024: ret = f"{num/1024:.1f}k"
  elif        num > 100: ret = f"{num:.0f}"
  else:		         ret = f"{num:.1f}"
  ret = re.sub("\.0([GMk])?$",r"\1",ret)
  return ret

# return time interval
def minsec(sec):
  ret = None
  if sec > 360000: ret = f"{sec/3600:.0f}hr"
  elif sec > 3600: ret = f"{sec/3600:.1f}hr"
  elif   sec > 60: ret = f"{sec/60:.1f}min"
  else:		   ret = f"{sec:.1f}sec"
  ret = re.sub("\.0((hr)|(min)|(sec))?$",r"\1",ret)
  return ret

# return layer size string: WIDTHxHEIGHT*CHANNELS
def lsz(size): return f"{size[0]}x{size[1]}*{size[2]}"
  
# ----------------------------------------------- get directory name from command-line
PACKAGE="imclust"
VERSION="0.2"

HELP = f"""
NAME
    imclust - cluster images

USAGE
    imclust [OPTIONS] DIRECTORY...

DESCRIPTION
    Imclust does cluster images in the directory, and produces
    a web visualization (or CSV-file output). Clustering is done
    in six steps:

       1. loading and resize of images,
       2. perception - transformation of images into vectors,
       3. reduction of dimensionality of vectors (optional),
       4. clustering,
       5. ordering/sorting of clusters,
       6. assembling the visualization or the output data-file.

    Caching of perception and reduction outputs can be enabled.

OPTIONS
      -h  This help.
      -v  Verbose.
      -f  Force recomputing all data, avoid cached.
    -csv  Write csv output instead of html.
 -o PATH  Output file name.
  -j NUM  Number of threads for loading, dflt. {THREADS}.
  -cache  Cache computed vectors for every picture (see -vec).
  -c NUM  Requested number of clusters.
  -m NUM  Limit the max number of images to cluster.
 -mt NUM  Number of members threshold for the cluster to be accepted.
 -dt NUM  Absolute distance threshold from the center cluster, for
          the image to be accepted.
-pt PERC  Percentual threshold.
  -b NUM  Batch size.
  -r NUM  Reduce vector dimensionality to NUM, dflt. auto from {REDIMSIZE}.
 -rp NUM  No. of patterns to train reduction, dflt. auto from {REDIMPATS}.
 -nn STR  Model name, dflt. {MODEL} (from {", ".join(MODELS)}).
 -cl STR  Clustering algorithm, dflt. {CLUST} (from {", ".join(CLUSTS)}).
 -rd STR  Dimensionality reduction, dflt. {REDIM} (from {", ".join(REDIMS)}).
  -s STR  Sorting of cluster centers, dflt. {SORT} (from {", ".join(SORTS)}).
-vec STR  Suffix of files with precomputed vectors for every picture,
          for "dir/f_12.jpg" we expect "dir/f_12.vgg" if STR is "vgg".
          Comma separated list of suffixes is allowed, to concatenate
          several vectors into single input for clustering.

CLUSTERING
      km  scikit KMeans
     bkm  scikit MiniBatchKMeans

VERSION
    imclust {VERSION} (c) R.Jaksa 2021
"""

import argparse
parser = argparse.ArgumentParser(add_help=False)
parser.add_argument("-h","--help",action="store_true")
parser.add_argument("-v","--verbose",action="store_true")
parser.add_argument("-csv","--csv",action="store_true")
parser.add_argument("-c","--clusters",type=int)
parser.add_argument("-m","--maximum",type=int)
parser.add_argument("-dt","--distthr",type=int)
parser.add_argument("-pt","--percthr",type=int)
parser.add_argument("-o","--output",type=str)
parser.add_argument("-j","--threads",type=int)

parser.add_argument("-b","--batchsize",type=int)
parser.add_argument("-r","--redimsize",type=int)
parser.add_argument("-rp","--redimpats",type=int)

parser.add_argument("-nn","--nn",type=str,default=MODEL)
parser.add_argument("-cl","--clust",type=str,default=CLUST)
parser.add_argument("-s","--sort",type=str,default=SORT)
parser.add_argument("-rd","--redim",type=str)

parser.add_argument("-vec","--vectors",type=str)
parser.add_argument("-cache","--cache",action="store_true")
parser.add_argument("paths",type=str,nargs='*')
args = parser.parse_args()

if args.help:
    print(HELP)
    exit(0)

VERBOSE = 1 if args.verbose else 0
if args.threads: THREADS = args.threads

if not args.nn in MODELS: MSGE(f"unknown perc. model {args.nn}")
else: MODEL = args.nn

if not args.clust in CLUSTS: MSGE(f"unknown clustering {args.clust}")
else: CLUST = args.clust

if not args.redim and args.vectors: REDIM = "none"
if args.redim == None: pass
elif not args.redim in REDIMS: MSGE(f"unknown dim. reduction {args.redim}")
else: REDIM = args.redim

if not args.sort in SORTS: MSGE(f"unknown sorting {args.sort}")
else: SORT = args.sort

# ------------------------------------------------------------------ get list of files
from glob import glob
import random

MSG1("scan paths")
paths = [] # paths to pictures
poor = [] # wrong/missing paths
for name in args.paths:

  # 1st: from CSV (use the 1st column and expect filenames)
  if re.search("\.csv$",name):
    for file in os.popen(f"cut -d ' ' -f 1 {name}").read().rstrip().split("\n"):
      if file[0] == "#": continue
      if os.path.exists(file): paths.append(file)
      else: poor.append(file)

  # 2nd: explicit filenames
  elif re.search("\.((png)|(jpg))$",name):
    if os.path.exists(name): paths.append(name)
    else: poor.append(name)

  # 3rd: recursive directory search
  elif os.path.isdir(name):
    paths += glob(name+"/**/*.png",recursive=True)
    paths += glob(name+"/**/*.jpg",recursive=True)

  else: poor.append(name)

MSG2(f"{len(paths)} pictures")

# limit the number of files to process
if args.maximum and args.maximum < len(paths):
  paths = paths[:args.maximum]
  MSG2(f"(limit to {len(paths)})")
MSG3("")

# errors
if poor:
  MSGE(f"wrong pathnames: {', '.join(poor)}")
if len(paths)<1:
  MSGE("cannot proceed without files")

# remove duplicates and shuffle
paths = list(set(paths))
random.shuffle(paths)

#for p in paths: print(p)
# --------------------------------------------------------------------- batching setup

def  modelname(model): return model._name
def  inputsize(model): return model._feed_input_shapes[0][1:]
def outputsize(model): return model.outputs[0].shape[1:]

# ------------------------------------------------------------------------------------

# just return the input/output/vector sizes, without model loading
def modelsize(name):
  if name == "resnet50": return (224,224,3),(7,7,2048),100352
  if name == "none": return (128,128,3),(128,128,3),49152

# get sizes from model...
def realsize(prcpt):
  if prcpt.name == "none": return modelsize(prcpt.name)
  osize = outputsize(prcpt.model)
  return inputsize(prcpt.model),osize,osize[0]*osize[1]*osize[2]
  
# load model by name and return "prcpt" structure
def perception_init(cache,name,isize,osize,vsize):
  prcpt = types.SimpleNamespace()
  prcpt.name = name

  if name == "none":
    prcpt.vsize = vsize
  else:
    prcpt.isize,prcpt.osize,prcpt.vsize = modelsize(name)

  if name == "none": return prcpt	# no model for none model
  if cache.paths0: pass			# needs model for loading
  elif cache.paths0all: pass		# probably needs for redim
  else: return prcpt

  # tensorflow models start here
  MSG1("init perception")
  if not VERBOSE: os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
  import tensorflow as tf

  if name == "resnet50":
    prcpt.model = tf.keras.applications.resnet50.ResNet50(include_top=False,weights="imagenet",input_shape=(224,224,3))

  prcpt.name = modelname(prcpt.model)
  prcpt.isize,prcpt.osize,prcpt.vsize = realsize(prcpt)
  MSG3(f"{prcpt.name} {lsz(prcpt.isize)} -> {lsz(prcpt.osize)} = {prcpt.vsize}")
  if isize!=prcpt.isize or osize!=prcpt.osize or vsize!=prcpt.vsize:
    MSGE("perception size mismatch, was: {lsz(isize)} -> {lsz(osize)} = {vsize}")
  return prcpt

# ------------------------------------------------------------------------------------

def perceive(prcpt,images):
  vectors = prcpt.model.predict(images)
  vectors = vectors.reshape(images.shape[0],-1)
  return vectors

# ------------------------------------------------------------------------------------

isize,osize,vsize = modelsize(MODEL)

if args.batchsize: BATCHSIZE = args.batchsize
if args.redimsize: REDIMSIZE = args.redimsize
if args.redimpats: REDIMPATS = args.redimpats

if BATCHSIZE > len(paths): BATCHSIZE = len(paths)
if REDIMPATS > len(paths): REDIMPATS = len(paths)
if REDIMSIZE > REDIMPATS: REDIMSIZE = REDIMPATS

MSG("batch size",f"{BATCHSIZE} (aprox. {len(paths)/BATCHSIZE:.0f} batches)")

# -------------------------------------- cached loading of images till reduced vectors
import numpy as np

# numpy save float32 raw array
def saveraw(name,data):
  arr = np.array(data,"float32")
  file = open(name,"wb")
  arr.tofile(file)
  file.close()

# numpy load float32 raw array, as a concatenation of vectors from multiple files
def loadraw(base,sx):
  return np.concatenate([np.fromfile(re.sub("\.[a-z]*$",f".{s}",base),dtype="float32") for s in sx.split(",")])

# load batch of raw files into vectors, size is size of every vector
def loadraws(paths,sx):
  return np.array([loadraw(p,sx) for p in paths])

# load batch of raw files into vectors, size is size of every vector
def saveraws(paths,sx,vectors):
  i = 0
  for path in paths:
    saveraw(re.sub("\.[a-z]*$",f".{sx}",path),vectors[i])
    i += 1

# ------------------------------------------------------------------------------------

# MSG2 print of cached files
def MSG2cached(cache):
  l1  = len(cache.paths1)
  l2  = len(cache.paths2)
  l1a = len(cache.paths1all)
  if l2: MSG2(f"{l2} reduced,")
  if l1:
    MSG2(f"{l1} percepts")
    if l1a>l1: MSG2(f"(from {l1a})")
  elif l1a>l1: MSG2(f"{l1a} available percepts")
  if l1 or l2 or l1a>l1: MSG2("and")
  MSG3(f"{len(cache.paths0)} pictures not cached")

# scan cached files
def caching_init(paths,model,redim,redimsize):
  if redim == "none": redimsize = ""
  cache = types.SimpleNamespace()
  cache.sx1	  = f"{model}" # actual suffixe for perception cached files
  cache.sx2	  = f"{model}-{redim}{redimsize}" # perception+redim
  cache.sx1s	  = cache.sx1
  cache.paths0    = []	# paths to pictures (when no cache is available)
  cache.paths1    = []	# paths to model cache
  cache.paths2    = []	# paths to model + reducer
  cache.paths1all = []	# all available model-cached data
  cache.paths0all = []	# when no model cache is available

  MSG1("cache files")
  if redim == "none": MSG3(f"{cache.sx1} cache suffixes")
  else: MSG3(f"{cache.sx1} and {cache.sx2} cache suffixes")

  MSG1("cache status")

  if redim == "none":
    for p0 in paths:
      p1 = re.sub("\.[a-z]*$",f".{cache.sx1}",p0)
      if os.path.exists(p1):
        cache.paths1.append(p0)
        cache.paths1all.append(p0)
      else:
        cache.paths0.append(p0)
        cache.paths0all.append(p0)
  else:
    for p0 in paths:
      p1 = re.sub("\.[a-z]*$",f".{cache.sx1}",p0)
      p2 = re.sub("\.[a-z]*$",f".{cache.sx2}",p0)
      if   os.path.exists(p2):	cache.paths2.append(p0)
      elif os.path.exists(p1):	cache.paths1.append(p0)
      else:			cache.paths0.append(p0)
      if os.path.exists(p1):	cache.paths1all.append(p0)
      else:			cache.paths0all.append(p0)

  MSG2cached(cache)
  return cache

# input vectors from precomputed files by suffix
def caching_prec(paths,sx1s,redim,redimsize):
  if redim == "none": redimsize = ""
  cache = types.SimpleNamespace()
  sx1a = sx1s.split(",")			# array of (input) suffixes
  cache.sx1s = sx1s				# save orig string for loader
  cache.sx1 = re.sub(",","",sx1s)		# actual (output) file suffix
  cache.sx2 = f"{cache.sx1}-{redim}{redimsize}"	# inputs+redim
  cache.paths0    = []	# paths to pictures (when no cache is available)
  cache.paths1    = []	# paths to model cache
  cache.paths2    = []	# paths to model + reducer
  cache.paths1all = []	# all available model-cached data
  cache.paths0all = []	# when no model cache is available
  sizes = []		# list of sizes strings
  size = 0		# accumulated total size

  MSG("cache files",f"{' '.join(sx1a)} cache suffixes")
  MSG1("cache status")
  
  for p0 in paths:

    # for EVERY suffix, the file must exist
    allok = 1
    for sx in sx1a:
      p = re.sub("\.[a-z]*$",f".{sx}",p0)
      if not os.path.exists(p): allok = 0
    if not allok: continue

    # remember the image path
    cache.paths1.append(p0)
    cache.paths1all.append(p0)

    # get the size from 1st files
    if not size:
      for sx in sx1a:
        p = re.sub("\.[a-z]*$",f".{sx}",p0)
        sz = int(os.path.getsize(p)/4) # fro float 32
        size += sz
        sizes.append(str(sz))

  # fix the suffix
  if redim != "none" and vsize < redimsize:
    cache.sx2 = f"{cache.sx1}-{redim}{vsize}"

  MSG2cached(cache)
  MSG1("vectors size")
  if len(sizes)>1: MSG2(" + ".join(sizes) + " =")
  MSG3(f"{size:.0f}")
  return cache,size

# ------------------------------------------------------------------------------------
from multiprocessing.pool import ThreadPool
from imageio import imread
from skimage.transform import resize

# function to load and resize images
def lrworker(path,size):
  # print(f"---> {path}")
  # image = cv2.imread(path)
  # image = cv2.resize(image,size)
  # cv2.imwrite("/tmp/cv2.png",image)
  try:
    image = imread(str(path))
  except:
    print(f"\nmalformed image: {path}\n")
    return
  image = resize(image,size,anti_aliasing=True)
  return image

# load and resize images in a thread pool
def loadresize(paths,size):
  images = np.empty([0,size[0],size[1],size[2]],dtype=np.float32)
  pool = ThreadPool(THREADS)
  results = []
  for path in paths:
    results.append(pool.apply_async(lrworker,args=(path,size)))
  pool.close()
  pool.join()
  images = np.array([r.get() for r in results]) # assemble the batch-array
  return images

# the input loop: load + resize + nn + redim
def data_load(cache,prcpt,redim):

  # data loading setup
  needmodel = 0
  MSG1("loading setup")
  if cache.paths2: MSG2(f"{len(cache.paths2)} reduced vectors: just load,")
  if cache.paths1: MSG2(f"{len(cache.paths1)} percepts: load->{redim.name},")
  if cache.paths0:
    MSG2(f"{len(cache.paths0)} pictures: load+resize->{prcpt.name}->{redim.name},")
    needmodel = 1
  MSG3("\b\b ")

  # loading itself
  MSG1("load"); T1 = vtime()
  all_vectors = np.empty([0,redim.size],dtype=np.float32)
  images  = []	# 
  cached1 = []	# newly-cached list for perception vectors
  cached2 = []	# newly-cached list for dim-reduced vectors
  ibytes = 0	# accumulated hypothetical space needed for images
  j = 0		# batch index
  
  # 1st: cached already reduced dimensions -> just load
  i = 0 # image index
  end = len(cache.paths2)
  while i < end:
    i2 = i + BATCHSIZE
    if i2 > end: i2 = end
    MSGC("C")
    vectors = loadraws(cache.paths2[i:i2],cache.sx2)
    MSGP(j)
    all_vectors = np.concatenate((all_vectors,vectors),0)
    i += len(vectors)
    j += 1

  # 2nd: cached nn vectors -> only reduce dimensionality
  i = 0
  end = len(cache.paths1)
  while i < end:
    i2 = i + BATCHSIZE
    if i2 > end: i2 = end
    MSGC("c")
    vectors = loadraws(cache.paths1[i:i2],cache.sx1s)
    MSGC("\br")
    vectors = reduce(redim,vectors)
    if args.cache:
      saveraws(cache.paths1[i:i2],cache.sx2,vectors)
      cached2 += cache.paths1[i:i2]
    MSGP(j)
    all_vectors = np.concatenate((all_vectors,vectors),0)
    i += len(vectors)
    j += 1

  # 3rd: raw images -> load, resize, nn infer, reduce dim.
  i = 0
  end = len(cache.paths0)
  while i < end:
    i2 = i + BATCHSIZE
    if i2 > end: i2 = end
    MSGC("l")
    images = loadresize(cache.paths0[i:i2],prcpt.isize)
    ibytes += images.nbytes
    MSGC("\bn")
    vectors = perceive(prcpt,images)
    if args.cache:
      saveraws(cache.paths0[i:i2],cache.sx1,vectors)
      cached1 += cache.paths0[i:i2]
    MSGC("\br")
    vectors = reduce(redim,vectors)
    if args.cache:
      saveraws(cache.paths0[i:i2],cache.sx2,vectors)
      cached2 += cache.paths0[i:i2]
    MSGP(j)
    all_vectors = np.concatenate((all_vectors,vectors),0)
    i += len(vectors)
    j += 1

  # end
  T2 = vtime()

  MSG2("")
  if len(images): MSG2(f"{metric(ibytes)}B of {len(images)} images,")
  MSG2(f"{metric(all_vectors.nbytes)}B of {len(all_vectors)} vectors")
  MSG3(f"in {j} batches in {minsec(T2-T1)}")

  if cached1 or cached2:  MSG1("newly cached")
  if cached1:		  MSG2(f"{len(cached1)} percept. vectors")
  if cached1 and cached2: MSG2("and")
  if cached2:		  MSG2(f"{len(cached2)} reduced vectors")
  if cached1 or cached2:  MSG3("")

  return all_vectors
from sklearn.decomposition import PCA

def reduction_init(cache,prcpt,REDIM,REDIMSIZE,REDIMPATS):
  redim = types.SimpleNamespace()
  redim.name = REDIM
  redim.size = REDIMSIZE
  redim.pats = REDIMPATS
  redim.model = None
  cached = [] # newly-cached list for perception vectors

  # corrections for the none mode
  if redim.name == "none":
    redim.size = prcpt.vsize
    redim.pats = 0
  
  # redim not needed
  if cache.paths2 and not cache.paths1 and not cache.paths0: return redim
  if redim.name == "none": return redim

  # trainable modes
  MSG(f"{redim.name} setup",f"{prcpt.vsize} -> {redim.size} dimensions (from {redim.pats} samples)")

  # engine init
  redim.model = PCA(n_components=redim.size)
  # redim.model = cuml.PCA(n_components=redim.size)

  # loading
  MSG1(f"{redim.name} train"); T1 = vtime()
  j = 0 # batch index
  all_vectors = np.empty([0,prcpt.vsize],dtype=np.float32)

  # 1st: load cached vectors
  i = 0 # image index
  end = min(len(cache.paths1all),redim.pats)
  while i < end:
    i2 = i + BATCHSIZE
    if i2 > end: i2 = end
    MSGC("c")
    vectors = loadraws(cache.paths1all[i:i2],cache.sx1s)
    MSGP(j)
    all_vectors = np.concatenate((all_vectors,vectors),0)
    i += len(vectors)
    j += 1
  
  # 2nd: load raw images
  i = 0
  end = min(len(cache.paths0all),redim.pats)
  while i < end:
    i2 = i + BATCHSIZE
    if i2 > end: i2 = end
    MSGC("l")
    images = loadresize(cache.paths0all[i:i2],prcpt.isize)
    MSGC("\bn")
    vectors = perceive(prcpt,images)
    if args.cache:
      saveraws(cache.paths0all[i:i2],cache.sx1,vectors)
      cached += cache.paths0all[i:i2]
    MSGP(j)
    all_vectors = np.concatenate((all_vectors,vectors),0)
    i += len(vectors)
    j += 1

  # 3rd: train redim
  mem = all_vectors.nbytes
  MSGC("R"); T2 = vtime()
  redim.model.fit(all_vectors)

  # end
  MSGP(j); T3 = vtime()
  MSG2(f" {metric(mem)}B of vectors,")
  MSG2(f"{minsec(T2-T1)} loading,")
  MSG2(f"{minsec(T3-T2)} training time")
  MSG3("")

  # move newly cached vectors from paths0 to paths1
  if args.cache and cached:
    cache.paths0 = list(set(cache.paths0).difference(set(cached)))	# paths0 = paths0 - cached
    cache.paths1 = list(set(cache.paths1 + cached))			# paths1 = paths1 + cached
    MSG1("newly cached")
    MSG2(f"{len(cached)} pepcept. vectors, so we got")
    MSG2cached(cache)

  return redim

# ------------------------------------------------------------------------------------

def reduce(redim,vectors):

  if redim.name == "none":
    reduced = vectors
    #reduced = vectors.reshape(redim.size,-1)

  else:
    reduced = redim.model.transform(vectors)

  return reduced

# ------------------------------------------------------------------------------------

if args.vectors:
  cache,vsize = caching_prec(paths,args.vectors,REDIM,REDIMSIZE)
  MODEL = "none"
else:
  cache = caching_init(paths,MODEL,REDIM,REDIMSIZE)

REDIMSIZE = min(REDIMSIZE,vsize) # further reduce REDIMSIZE if vector size is too small
  
prcpt = perception_init(cache,MODEL,isize,osize,vsize)
redim =  reduction_init(cache,prcpt,REDIM,REDIMSIZE,REDIMPATS)
vectors =     data_load(cache,prcpt,redim)

# reorder paths, to have the "paths" in the same as "vectors" from loading
paths = []
for path in cache.paths2: paths.append(path)
for path in cache.paths1: paths.append(path)
for path in cache.paths0: paths.append(path)

IMAGES = len(vectors)

# ----------------------------------------------------------------------- cluster them
from sklearn import cluster
MSG1("clustering")

CLUSTERS = 128
if len(paths)<2048: CLUSTERS = int(len(paths)/16)
if CLUSTERS<2:	    CLUSTERS = 2
if args.clusters:   CLUSTERS = args.clusters

T0 = vtime()

if CLUST == "km":
  n_init = 10
  n_init = 2 if IMAGES>8000 else n_init
  knn = cluster.KMeans(n_clusters=CLUSTERS,verbose=VERBOSE,n_init=n_init)
  MSG2(f"scikit KMeans {CLUSTERS} clusters in {n_init} attempts")

if CLUST == "bkm":
  n_init = 2
  n_init = 10 if CLUSTERS<2001 else n_init
  n_init = 100 if CLUSTERS<101 else n_init
  knn = cluster.MiniBatchKMeans(n_clusters=CLUSTERS,verbose=VERBOSE,n_init=n_init)
  MSG2(f"scikit MiniBatchKMeans {CLUSTERS} clusters in {n_init} attempts")

dists = knn.fit_transform(vectors) # distances to all cluster centers
idx = knn.predict(vectors)	  # indexes of corresponding clusters
MSG3(f"in {minsec(vtime()-T0)}")

# distances to the closest cluster
dist = [np.inf] * IMAGES
for i in range(IMAGES):
  dist[i] = dists[i][idx[i]]
  #print(f"{i} {idx[i]} {dist[i]}")

# ------------------------------------------------------------------ organize clusters

# get per-cluster indexes and distances (needed to allow sorting)
cluster = []
cdist = []
for j in range(CLUSTERS):
  cluster.append([])
  cdist.append([])
for i in range(IMAGES):
  j = idx[i]
  cluster[j].append(i)
  cdist[j].append(dist[i])
#for j in range(CLUSTERS): print(f"{j}: {cluster[j]} {cdist[j]}")

# ordered indexes of images in clusters
ordered = [None]*CLUSTERS
for j in range(CLUSTERS):
  ordered[j] = [x for _,x in sorted(zip(cdist[j],cluster[j]))]
# for j in range(CLUSTERS): print(f"{j}: {ordered[j]} {cdist[j]}")

# obtain maximum distance from the cluster center
maxdist = 0
for i in range(IMAGES):
  if dist[i] > maxdist: maxdist = dist[i]

# compute percentage distances from the center for every image
pdist = [None]*IMAGES
for j in range(CLUSTERS):
  if ordered[j] == []: continue	# skip empty clusters
  d0 = dist[ordered[j][0]]		# distance of the closest image to the center
  for i in range(len(ordered[j])):
    k = ordered[j][i]
    pdist[k] = (maxdist-dist[k])/(maxdist-d0)*100

# compute active number of images in cluster (above thresholds)
above = [np.inf]*CLUSTERS
distthr = 0
percthr = 0
for j in range(CLUSTERS):
  if ordered[j] == []: continue
  for i in range(len(ordered[j])):
    k = ordered[j][i]
    if args.distthr and dist[k]>args.distthr:
      if i<above[j]:
        above[j] = i
        distthr += 1
    if args.percthr and pdist[k]<args.percthr:
      if i<above[j]:
        above[j] = i
        percthr += 1

if args.distthr:
  MSG1("distance threshold")
  MSG3(f"{distthr} images above {args.distthr}cm")
if args.percthr:
  MSG1("perc threshold")
  MSG3(f"{percthr} images below {args.percthr}%")

# ---------------------------------------------------------------------- sort clusters

# cindex = cluster indexes as sorted according to the number of elements
cindex = list(range(CLUSTERS))

# sort clusters according their size
if SORT == "size":
  elements = [len(x) for x in cluster]
  indexes  = list(range(CLUSTERS))
  cindex = [x for _,x in sorted(zip(elements,indexes),reverse=True)]

# sort clusters by tsp
if SORT == "tsp":
  from sklearn.metrics import pairwise_distances
  from python_tsp.distances import euclidean_distance_matrix
  from python_tsp.exact import solve_tsp_dynamic_programming
  from python_tsp.heuristics import solve_tsp_local_search, solve_tsp_simulated_annealing
  TSP = []
  TSP.append([]) 
  vectors2 = []
  #print(f"vectors:{len(vectors)}, ordered:{len(ordered)} clusters{CLUSTERS}")
  for j in range(CLUSTERS):
    #print(f"{j}-{ordered[j][0]}",end=" ")
    #print(f"{j}",end=" ")
    vectors2.append(vectors[ordered[j][0]])
  #print("")

  MSG1("distance matrix"); T1=vtime()
  mdist = euclidean_distance_matrix(vectors2)
  MSG3(f"{len(vectors2)}x{len(vectors2)} in {minsec(vtime()-T1)}")

  MSG1(f"{SORT}"); T1=vtime()
  permutation,distance = solve_tsp_simulated_annealing(mdist) 
  MSG3(f"{minsec(vtime()-T1)}")

  cindex = permutation

# TODO: listing only if requested
if 0:
  print("  i: ID  N")
  for j in range(CLUSTERS): print(f"{j+1:3}: {cindex[j]:<3} {elements[cindex[j]]:<3}")

# ------------------------------------------------ copy images according their cluster

# import shutil
# for i in range(IMAGES):
#   if not os.path.exists(f"output/cluster{cluster[i]}"): os.makedirs(f"output/cluster{cluster[i]}")
#   print(f"cp {paths[i]} output/cluster{cluster[i]}")
#   shutil.copy2(f"{paths[i]}",f"output/cluster{cluster[i]}")

# ------------------------------------------------------------ make html or csv output
# from web import *

CSS="""
html {
  background-color: #444051;
  font-family: 'Roboto Condensed', sans-serif; }
div {
  display: inline-block; }
div.box {
  vertical-align: middle;
  position: relative; }
h2 {
  color: white; }
.bad {
  position: relative;
  overflow: hidden; }
.bad:before, .bad:after {
  position: absolute;
  content: '';
  background: red;
  display: block;
  width: 75%;
  height: 8px;
  -webkit-transform: rotate(-45deg);
  transform: rotate(-45deg);
  left: 0;
  right: 0;
  top: 0;
  bottom: 0;
  margin: auto; }
.bad:after {
  -webkit-transform: rotate(45deg);    
  transform: rotate(45deg); }
"""

HTML="""<!DOCTYPE html>
<html>
<head>
<title>imclust</title>
<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Condensed:wght@700&display=swap" rel="stylesheet">
<style type="text/css">
{CSS}
</style>
</head>
<body>
{BODY}
<br><br><br><br>
</body>
</html>
"""

def addimg(path,clas,title,bad):
  b = " bad" if bad else ""
  s = ""
  s += f'<a href="{path}"><div class="box {clas}{b}">'
  s += f'<div><img class={clas} src="{path}" title="{title}"></div>'
  s += f'</div></a>\n'
  return s

# distribute all images into per-cluster html sections
section = [""]*CLUSTERS
for jj in range(CLUSTERS):		# j = cluster index as from kmeans
  j = cindex[jj]
  for i in range(len(ordered[j])):	# i = order in_the_cluster
    k = ordered[j][i]			# k = image_index
    bad = 1 if i>=above[j] else 0;
    if args.csv: # csv output
      section[j] += f"{paths[k]} {jj+1} {dist[k]:.1f} {pdist[k]:.1f} {bad}\n"
    else: # html output
      section[j] += addimg(f"{paths[k]}",f"cluster{jj+1}",f"{pdist[k]:.0f}% {dist[k]:.0f}cm",bad)

# output filename
output = "clust"
if args.output: output = args.output
output = re.sub("\.csv$","",output)
output = re.sub("\.html?$","",output)
MSG1("write output")

# save csv
BODY = ""
if args.csv:
  output = f"{output}.csv"
  for i in range(CLUSTERS):
    BODY += section[cindex[i]]
  with open(output,"w") as fd:
    fd.write("#path cluster dist pdist bad\n")
    fd.write(BODY)

# save html
else:
  output = f"{output}.html"
  for i in range(CLUSTERS):
    BODY += f"<h2>cluster {i+1}</h2>\n"
    BODY += section[cindex[i]]
    BODY += "\n\n"
  html = HTML.format(BODY=BODY,CSS=CSS)
  with open(output,"w") as fd:
    fd.write(html)

MSG3(output)
# ------------------------------------------------------------------------------------
